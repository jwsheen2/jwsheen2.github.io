---
title: 위시캣 견적 - 숙소, 사우나, 음식점, 시설출입
date: 2099-01-11
layout: post #default
subtitle: 위시캣
# image:
#   path: /assets/img/맛-산해진미-한정식.webp
tags: [daily]
comments: true
author: 잠자리
---

## NIST '적대적 머신러닝(ML): 공격 및 완화에 대한 분류와 용어' 
[NIST.AI.100-2e2023](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)

> 보안 및 개인정보 보호 문제에는 훈련 데이터의 악의적 조작 가능성, AI 시스템의 성능에 악영향을 미치기 위한 모델 취약성의 악의적 악용, 심지어 데이터에 표현된 사람, 모델 자체 또는 독점 기업 데이터에 대한 민감한 정보를 유출하기 위한 악의적 조작, 수정 또는 모델과의 단순한 상호 작용 등이 포함됩니다

> 회피, 중독, 남용, 프라이버시

## 회피 Evasion attack
: 회피 공격(Evasion attack)은 AI시스템이 **배포된 후 발생**한다. **입력을 변경**해 시스템이 응답하는 방식을 변경하는 공격이다. 

예: 자율주행자동차가 인식하는 정지 표시판을 속도제한 표지판으로 잘 못 해석하게 한다. 
혼란스러운 차선 표시를 만들어 차량이 도로를 벗어나게 한다.

## 중독 Poisoning attack
: 중독 공격(Poisoning attack)은 손상된 데이터를 삽입해 AI시스템 **훈련 단계에서 발생**한다. 훈련 데이터 세트를 조작하는 공격이다. 공격자가 ML 모델에 부정확하거나 잘못 해석된 데이터를 공급해 잘못된 예측을 내놓게 만든다. 공격자가 훈련 데이터 중 일부에 부적절한 내용을 넣는다. AI 모델이 사용하는 데이터세트의 0.1%만 중독해도 성공적인 조작으로 이어질 수 있는 것으로 나타났다. 

예: 위키피디아(Wikipedia)와 같은 Cloud 소스 정보 저장소 등을 악용해 LLM 모델을 간접적으로 조작할 수도 있다. 

## 남용 Abuse attack
: 남용 공격(Abuse attack)은 피싱 이메일을 생성하거나 악성코드 작성과 같이 악성 콘텐츠를 생성하기 위해 AI 도구를 무기화하는 것이 포함된다. 

예: 다크웹에서 프러드(Fraud)GPT나 웜(Worm)GPT와 같이 사이버 범죄를 지원하는 LLM 서비스가 나왔다. 

## 프라이버시 Privacy attack
: 프라이버시 공격(Privacy attack)은 AI가 훈련한 데이터 중 민감 정보를 추출해 이를 오용하는 시도다. 

예: 공격자는 챗봇에게 다양한 질문을 한 후 모델을 **리버스 엔지니어링해 약점을 찾거나 원본을 추측**할 수 있다.

<hr/>

* Predictive AI(PredAI) 에측형
: 통계 분석을 사용하여 패턴을 식별하고, 행동을 예측하며, 향후 이벤트를 예측

* Generative AI(GenAI) 생성형
: ....